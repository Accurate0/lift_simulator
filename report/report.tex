\documentclass[12pt,titlepage]{article}
\usepackage{geometry}
\usepackage{minted}
\usepackage[T1]{fontenc}
\usepackage[hidelinks]{hyperref}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{appendix}
\usepackage{pdfpages}
% \usepackage{listings}

\setminted[c]{linenos, frame=single, breaklines}
\setminted[md]{linenos, frame=single, breaklines}

% \usemintedstyle{friendly}
% a4paper is 210 by 297
\geometry{a4paper, total={170mm,242mm}}
\setlength{\parindent}{0em}
\setlength{\parskip}{0.5em}

\begin{document}
\includepdf[pages=-]{../declaration_of_originality.pdf}
\hypersetup{pageanchor=false}

\begin{titlepage}
    \centering
    \vfill
    \vspace{1cm}
    {\scshape\Large Operating Systems\par}
    \vfill
    {\huge\bfseries Lift Simulator - Report\par}
    \vspace{2cm}
    {\Large\itshape{Anurag Singh}\par}
    {\Large 18944183\par}
    \vfill
    {\large \today\par}
\end{titlepage}

\pagenumbering{roman}
\tableofcontents
\newpage
\pagenumbering{arabic}
\hypersetup{pageanchor=true}

\section{Mutual Exclusion and Shared Resources}
\subsection{Threads}
Mutual exclusion is done using pthread mutexes the queue struct contains a mutex that is used to protect the data inside the queue, this mutex must be acquired before manipulating queue data to ensure mutual exclusion, this queue is shared between the scheduler thread and the 3 lift threads, and if any of them wish to mutate the queue in any way (removing or adding) they must first acquire mutex.

2 conditions are also used to allow some basic communication between threads, the conditions are when the queue is empty or full, if the queue is empty the lift threads wait until the scheduler adds something to the queue, and signals the condition waking up a sleeping thread to reacquire the mutex and to process the data, and in the case of the queue been full.

\begin{minted}{c}
...
pthread_mutex_lock(&l->queue->mutex);
...

while(l->queue->empty && !l->queue->finished) {
    pthread_cond_wait(&l->queue->cond_empty, &l->queue->mutex);
}

if(!l->queue->empty) {
    request_t *r = queue_remove(l->queue);
    pthread_cond_signal(&l->queue->cond_full);
    pthread_mutex_unlock(&l->queue->mutex);
...
\end{minted}


The scheduler waits on a full condition which is signaled by any of the 3 lift threads when they remove something from the queue, letting the scheduler know that there is space now and it can wake up an reacquire the mutex to add more into the queue.

\begin{minted}{c}
...
pthread_mutex_lock(&s->queue->mutex);

while(s->queue->full) {
    pthread_cond_wait(&s->queue->cond_full, &s->queue->mutex);
}

request_t *r = file_read_line(s->input);
if(r) {
    queue_add(s->queue, r);
...
pthread_mutex_unlock(&s->queue->mutex);
...
\end{minted}

\subsection{Processes}
A logic similar to threads exists in processes but requires the use of shared memory and semaphores since processes do not share memory mappings the way threads do.

I used POSIX shared memory and semaphores in order to implement shared resources and mutual exclusion. The bounded buffer problem can be solved through the use of 3 semaphores, one acting as a signal for full, another as a signal for empty, and the final used as a mutex to protect the shared memory (I also had another to protected accesses to the output file). The semaphores are initialised to different values.

\begin{minted}{c}
sem_init(&ptr->semaphore.empty, 1, m);
sem_init(&ptr->semaphore.full, 1, 0);
sem_init(&ptr->semaphore.mutex, 1, 1);
sem_init(&ptr->semaphore.file, 1, 1);
\end{minted}

The empty semaphore marks how many empty locations are in the buffer, the full semaphore marks how many are full, the mutex is used as a binary semaphore to protect the shared memory and same for the file semaphore to protect the file IO.

The scheduler must wait on the empty mutex to be available in order to add something into the shared memory, and once it has added something the scheduler posts the full mutex to allow a lift process to wake up and take one from the queue, once the lift is done it posts another empty, which will allow the scheduler back on if the queue was completely full prior.

The mutex semaphore is used to protect the shared memory by enforcing mutual exclusion by only allowing a single process to modify the data in the shared memory.

In terms of the shared resources, there was an array of requests which was used as a circular queue, and the semaphores were also shared, along with some statistics that need to be printed such as total requests and the movement counts of each individual lift.

These resources were shared through the use of the POSIX shared memory API, this API required you to open a shared memory object with a name, use \texttt{ftruncate} to set the size of the shared memory object, and to use \texttt{mmap} to map the memory object into the address space of the current process. This was done once to create the shared memory by the main, and then each process mapped the same block of shared memory into their own address space.

Once the processes have been \texttt{wait}ed on, the shared memory is unmapped and the memory objects are unlinked.

The output \texttt{FILE} isn't included in the shared memory since according to the manual page for \texttt{fork}, the open file descriptors are shared across child processes, therefore the parent simply opens it, and each child will close it when they're done, and same for the parent.

\newpage
\section{Testing - Processes}
Each test file is a different size between the allowed values of 50 and 100.
\subsection{Example 1}
Testing with a buffer size larger than the number of threads, and relatively small sleep time to see if the program behaves as expected. Through manual inspection of the output, it can be surmised that the program works as expected.

\paragraph{Command}\texttt{./lift\_sim\_B 4 2 test/inputs/test2.txt}

\paragraph{Input}
\texttt{test/inputs/test2.txt}

\paragraph{Output}
\texttt{examples/process/test2.out}

\subsection{Example 2}
Testing with a significantly larger buffer size but with a sleep time of 0 to see if mutual exclusion still exists in the case of the ``work'' being done quickly. Manual inspection reveals the expected output, and since there was a final output, it means there was no deadlock while acquiring resources.

\paragraph{Command}\texttt{./lift\_sim\_B 10 0 test/inputs/test7.txt}

\paragraph{Input}
\texttt{test/inputs/test7.txt}

\paragraph{Output}
\texttt{examples/process/test7.out}

\subsection{Example 3}
A very large buffer size with a long sleep time to demonstrate another possible situation where the program works as expected.

\paragraph{Command}\texttt{./lift\_sim\_B 20 5 test/inputs/test21.txt}

\paragraph{Input}
\texttt{test/inputs/test21.txt}

\paragraph{Output}
\texttt{examples/process/test21.out}

\newpage
\section{Testing - Threads}
Each test file is a different size between the allowed values of 50 and 100.
\subsection{Example 1}
A buffer size equal to to the number of worker threads with a relatively short ``working'' time.

\paragraph{Command}\texttt{./lift\_sim\_A 3 1 test/inputs/test34.txt}

\paragraph{Input}
\texttt{test/inputs/test34.txt}

\paragraph{Output}
\texttt{examples/threads/test34.out}


\subsection{Example 2}
Larger buffer with the same time.

\paragraph{Command}\texttt{./lift\_sim\_A 5 1 test/inputs/test1.txt}

\paragraph{Input}
\texttt{test/inputs/test1.txt}

\paragraph{Output}
\texttt{examples/threads/test1.out}


\subsection{Example 3}
Even larger buffer with a zero time to ensure mutual exclusion happens even without the threads sleeping.

\paragraph{Command}\texttt{./lift\_sim\_A 10 0 test/inputs/test10.txt}

\paragraph{Input}
\texttt{test/inputs/test10.txt}

\paragraph{Output}
\texttt{examples/threads/test10.out}

\newpage

\begin{appendices}
    \section{Source Code}
    \subsection{README.md}
    \inputminted{md}{../README.md}
    \newpage
    \subsection{Common}
    \subsubsection{common.h}
    \inputminted{c}{../src/common/common.h}
    \subsubsection{file\_io}
    \inputminted{c}{../src/common/file_io.h}
    \inputminted{c}{../src/common/file_io.c}
    \subsubsection{request.h}
    \inputminted{c}{../src/common/request.h}
    \subsection{Processes}
    \subsubsection{cqueue}
    \inputminted{c}{../src/process/cqueue.h}
    \inputminted{c}{../src/process/cqueue.c}
    \subsubsection{lift\_main}
    \inputminted{c}{../src/process/lift_main.h}
    \inputminted{c}{../src/process/lift_main.c}
    \subsubsection{memory}
    \inputminted{c}{../src/process/memory.h}
    \inputminted{c}{../src/process/memory.c}
    \subsubsection{scheduler\_main}
    \inputminted{c}{../src/process/scheduler_main.h}
    \inputminted{c}{../src/process/scheduler_main.c}
    \subsubsection{lift\_sim\_B}
    \inputminted{c}{../src/process/lift_sim_B.c}
    \subsection{Threads}
    \subsubsection{lift}
    \inputminted{c}{../src/thread/lift.h}
    \inputminted{c}{../src/thread/lift.c}
    \subsubsection{log}
    \inputminted{c}{../src/thread/log.h}
    \inputminted{c}{../src/thread/log.c}
    \subsubsection{queue}
    \inputminted{c}{../src/thread/queue.h}
    \inputminted{c}{../src/thread/queue.c}
    \subsubsection{scheduler}
    \inputminted{c}{../src/thread/scheduler.h}
    \inputminted{c}{../src/thread/scheduler.c}
    \subsubsection{lift\_sim\_A}
    \inputminted{c}{../src/thread/lift_sim_A.c}
\end{appendices}

\end{document}
